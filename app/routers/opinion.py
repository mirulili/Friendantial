# app/routers/opinion/opinion.py

import httpx
import redis.asyncio as redis
from fastapi import APIRouter, Depends, Query, Request
from jinja2 import Environment

from app.dependencies import (get_http_client, get_jinja_env,
                              get_redis_connection, get_llm_client)
from app.llm.llm_service import generate_text_with_persona
from app.llm.prompt_builder import build_prompt
from app.schemas.enums import PersonaEnum
from app.services.analysis import AnalysisService

# APIRouter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
router = APIRouter(
    tags=["opinion"],
)


def get_analysis_service(
    request: Request,
) -> AnalysisService:
    """FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœì—ì„œ AnalysisServiceë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return request.app.state.analysis_service


@router.get("/opinion/{stock_code}", summary="ì¢…ëª© ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€ (RAG)")
async def ask_about_stock(
    request: Request,
    stock_code: str,
    question: str = Query(..., description="ì§ˆë¬¸ ë‚´ìš© (ì˜ˆ: ì™œ ë–¨ì–´ì ¸?)"),
    persona: PersonaEnum = Query(PersonaEnum.FRIEND, description="ë‹µë³€ í˜ë¥´ì†Œë‚˜ ì„ íƒ"),
    analysis_service: AnalysisService = Depends(get_analysis_service),
    client: httpx.AsyncClient = Depends(get_http_client),
    jinja_env: Environment = Depends(get_jinja_env),
    redis_conn: redis.Redis = Depends(get_redis_connection),
    llm_client: httpx.AsyncClient = Depends(get_llm_client),
):
    """
    íŠ¹ì • ì¢…ëª©ì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ (RAG ì ìš©).
    """
    # 1. ê¸°ë³¸ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê¸°ìˆ ì  ë¶„ì„ + ë‰´ìŠ¤)
    analysis_result = await analysis_service.get_detailed_stock_analysis(stock_code)
    stock_name = analysis_result["stock_name"]
    tech_analysis = analysis_result["technical_analysis"]
    news_titles = [item['title'] for item in analysis_result["news_analysis"]["details"]]

    # 2. ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ë‹µë³€ ë°˜í™˜
    if not news_titles:
        return {"answer": "ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í•´ì„œ ë‹µë³€í•˜ê¸° ì–´ë ¤ì›Œ ğŸ˜¢"}

    # 3. RAG: ë²¡í„° DBì— ì €ì¥ ë° ê²€ìƒ‰
    rag_engine = request.app.state.rag_engine
    # (1) ì§€ì‹ ì €ì¥ (Ingestion)
    rag_engine.create_collection(stock_code, news_titles)

    # (2) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (Retrieval)
    relevant_news = rag_engine.query(stock_code, question, n_results=5)  # type: ignore

    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context_text = "\n".join([f"- {title}" for title in relevant_news])

    user_prompt = build_prompt(
        jinja_env,
        "rag/rag_opinion.jinja2",  # âœ… ê²½ë¡œ ìˆ˜ì • (../ ì œê±°)
        stock_name=stock_name,
        stock_code=stock_code,
        context_text=context_text,
        tech_analysis=tech_analysis,
        question=question,
    )

    # 5. LLM ë‹µë³€ ìƒì„±
    answer = await generate_text_with_persona(
        persona_name=persona.value,
        user_prompt=user_prompt,
        llm_client=llm_client,
        redis_conn=redis_conn,
        jinja_env=jinja_env,
    )

    return {
        "stock": stock_name,  # type: ignore
        "question": question,
        "context_used": relevant_news,  # ì–´ë–¤ ë‰´ìŠ¤ë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ ëª…ì‹œ
        "answer": answer,
    }
