import httpx
from fastapi import APIRouter, Depends, Query, Request

from app.dependencies import get_http_client
from app.schemas.enums import PersonaEnum
from app.services.llm_service import generate_text_with_persona
from app.services.market_data import get_stock_name_from_code
from app.services.prompt_builder import build_prompt
from app.services.rag import rag_engine
from app.services.sentiment import fetch_news_titles

# APIRouter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
router = APIRouter(
    tags=["opinion"],  # API ë¬¸ì„œì—ì„œ 'recommendations' ê·¸ë£¹ìœ¼ë¡œ ë¬¶ìŒ
)


@router.get("/opinion/{stock_code}", summary="ì¢…ëª© ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€ (RAG)")
async def ask_about_stock(
    request: Request,
    stock_code: str,
    question: str = Query(..., description="ì§ˆë¬¸ ë‚´ìš© (ì˜ˆ: ì™œ ë–¨ì–´ì ¸?)"),
    persona: PersonaEnum = Query(PersonaEnum.FRIEND, description="ë‹µë³€ í˜ë¥´ì†Œë‚˜ ì„ íƒ"),
    client: httpx.AsyncClient = Depends(get_http_client),
):
    """
    íŠ¹ì • ì¢…ëª©ì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ (RAG ì ìš©).
    """
    # 1. ì¢…ëª©ëª… ì¡°íšŒ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
    stock_name = await get_stock_name_from_code(request, client, stock_code)
    news_titles = await fetch_news_titles(client, stock_name, limit=15)

    if not news_titles:
        return {"answer": "ê´€ë ¨ëœ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í•´ì„œ ë‹µë³€í•˜ê¸° ì–´ë ¤ì›Œ ğŸ˜¢"}

    # 3. RAG: ë²¡í„° DBì— ì €ì¥ ë° ê²€ìƒ‰
    # (1) ì§€ì‹ ì €ì¥ (Ingestion)
    rag_engine.create_collection(stock_code, news_titles)

    # (2) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (Retrieval)
    relevant_news = rag_engine.query(stock_code, question, n_results=5)

    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Context Stuffing)
    context_text = "\n".join([f"- {title}" for title in relevant_news])

    user_prompt = build_prompt(
        request,
        "rag_opinion.jinja2",
        stock_name=stock_name,
        stock_code=stock_code,
        context_text=context_text,
        question=question,
    )

    # 5. LLM ë‹µë³€ ìƒì„±
    answer = await generate_text_with_persona(
        request=request,
        persona_name=persona.value,
        user_prompt=user_prompt,
        llm_client=request.app.state.llm_client,
    )

    return {
        "stock": stock_name,
        "question": question,
        "context_used": relevant_news,  # ì–´ë–¤ ë‰´ìŠ¤ë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ ëª…ì‹œ
        "answer": answer,
    }
